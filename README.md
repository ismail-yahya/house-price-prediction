# üè† House Prices Prediction ‚Äî Advanced Regression Techniques

This project uses the **[Kaggle House Prices dataset](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)** to build and evaluate multiple regression models for predicting house sale prices.  
Through feature engineering, missing value handling, and model evaluation, we aimed to achieve high accuracy in price prediction.

---

## üìä Project Overview

The project follows these main steps:

1. **Exploratory Data Analysis (EDA)**

   - Visual and statistical analysis of numerical and categorical features.
   - Examined correlations between features and the target variable `SalePrice` (before and after log transformation).

2. **Missing Value Handling**

   - Categorical features: replaced missing values with `"None"`.
   - Numerical features: filled with `0` or median depending on context.

3. **Outlier Removal**

   - Removed records with extremely high square footage or unusually high/low sale prices.

4. **Feature Engineering**

   - Created new meaningful features:
     - `TotalSF` ‚Äî Total square footage.
     - `Total_Bathrooms` ‚Äî Total bathrooms count.
     - `Total_Home_Quality` ‚Äî Combined quality score.
     - Age-related features for house construction and renovation.
     - Binary indicators for the presence of a pool, garage, or basement.

5. **Encoding Categorical Features**

   - Applied **Ordinal Encoding** to ordered categories.
   - Used **One-Hot Encoding** for nominal categories.

6. **Model Training & Evaluation**

   - Tested multiple models:
     - **Linear Regression** ‚Üí RMSE CV: `0.1243`
     - **Decision Tree** ‚Üí RMSE CV: `0.1999`
     - **Random Forest** ‚Üí RMSE CV: **`0.1319`**
     - **XGBoost** ‚Üí RMSE CV: `0.1322`
   - Best performance achieved with **Random Forest**.

7. **Final Results**
   - XGBoost model RMSE on validation: **`0.1306`**
   - Submission file generated for Kaggle competition.

---

## **Technologies Used**

- Python 3.x
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- XGBoost
- Jupyter Notebook

---

## üìà Results

- **Best Model:** XGBoost
- **Validation RMSE:** `0.12158`
- **Kaggle Public Score:** `0.12637`

---

## üìÇ Dataset

The dataset used in this project can be accessed here:  
üîó **[House Prices - Advanced Regression Techniques on Kaggle](https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques)**
